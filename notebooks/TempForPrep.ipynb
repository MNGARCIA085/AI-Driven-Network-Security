{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d8e01-dbb0-498b-b6b2-6ac0ca73f552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dd8661f-6521-4559-aa7c-fb18fdb07263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'ascii', 'confidence': 1.0, 'language': ''}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "chardet.detect(open(\"../data/train_val_data.csv\",'rb').read(400000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6cd717-c1cb-4037-86f4-9343a7d2bfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a7a89-5928-4778-9247-4272017e2a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b937929-de9e-4e66-9beb-d67040ed9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30b3c37d-2f14-4612-bae7-4c3f8376c9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61900</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24800</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443</td>\n",
       "      <td>5885346</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>710</td>\n",
       "      <td>3826</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>78.888889</td>\n",
       "      <td>172.656773</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>292949.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292949</td>\n",
       "      <td>292949</td>\n",
       "      <td>5592381.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5592381</td>\n",
       "      <td>5592381</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49738</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>98306933</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>363</td>\n",
       "      <td>11595</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>139.406958</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>14018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14018</td>\n",
       "      <td>14018</td>\n",
       "      <td>98300000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98300000</td>\n",
       "      <td>98300000</td>\n",
       "      <td>DoS Hulk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Destination Port  Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0             61900             54                  2                       2   \n",
       "1             24800             49                  2                       0   \n",
       "2               443        5885346                  9                       6   \n",
       "3             49738             57                  1                       1   \n",
       "4                80       98306933                  6                       7   \n",
       "\n",
       "   Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "0                            4                           12   \n",
       "1                            4                            0   \n",
       "2                          710                         3826   \n",
       "3                            0                            0   \n",
       "4                          363                        11595   \n",
       "\n",
       "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "0                      2                      2                2.000000   \n",
       "1                      2                      2                2.000000   \n",
       "2                    517                      0               78.888889   \n",
       "3                      0                      0                0.000000   \n",
       "4                    345                      0               60.500000   \n",
       "\n",
       "   Fwd Packet Length Std  ...  min_seg_size_forward  Active Mean  Active Std  \\\n",
       "0               0.000000  ...                    24          0.0         0.0   \n",
       "1               0.000000  ...                    24          0.0         0.0   \n",
       "2             172.656773  ...                    32     292949.0         0.0   \n",
       "3               0.000000  ...                    32          0.0         0.0   \n",
       "4             139.406958  ...                    20      14018.0         0.0   \n",
       "\n",
       "   Active Max  Active Min   Idle Mean  Idle Std  Idle Max  Idle Min     Label  \n",
       "0           0           0         0.0       0.0         0         0    BENIGN  \n",
       "1           0           0         0.0       0.0         0         0    BENIGN  \n",
       "2      292949      292949   5592381.0       0.0   5592381   5592381    BENIGN  \n",
       "3           0           0         0.0       0.0         0         0    BENIGN  \n",
       "4       14018       14018  98300000.0       0.0  98300000  98300000  DoS Hulk  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train_val_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f38437dd-8f27-48ab-a74d-f4d417469f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79998, 79)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3a452f4-58d2-4703-928b-e1c2f4f9f8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77340, 79)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c686aa04-d272-4764-9c5a-34f26694dd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77305, 79)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.dropna()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5c0f4d0-dff0-4127-871d-50b58c78da84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77305, 45)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns to keep (featiure engineering)\n",
    "\n",
    "# List of features to keep\n",
    "keep_features = [\n",
    "    'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
    "    'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
    "    'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
    "    'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std',\n",
    "    'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
    "    'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min',\n",
    "    'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min',\n",
    "    'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count',\n",
    "    'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags',\n",
    "    'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'Down/Up Ratio', 'Average Packet Size',\n",
    "    'Label'  # Keep the target\n",
    "]\n",
    "\n",
    "\n",
    "# Keep only the selected columns\n",
    "df = df[keep_features]\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f326811-6e6f-424c-9f83-aa8aaad324a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENIGN              63101\n",
      "DoS Hulk             5162\n",
      "PortScan             4373\n",
      "DDoS                 3618\n",
      "DoS GoldenEye         291\n",
      "FTP-Patator           189\n",
      "DoS slowloris         162\n",
      "DoS Slowhttptest      155\n",
      "SSH-Patator           138\n",
      "Other_Attack          116\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# combine rare attacks\n",
    "\n",
    "# Define rare attacks to combine\n",
    "rare_attacks = ['Bot', 'Web Attack � Brute Force', 'Web Attack � XSS']\n",
    "\n",
    "# Create a new column or overwrite Label\n",
    "df['Label'] = df['Label'].apply(lambda x: 'Other_Attack' if x in rare_attacks else x)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48744979-0d11-40b3-aa5a-5c6cd659a2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77305, 45)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8841a8ff-1310-4f97-a9d9-ebc6cd4bd0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'BENIGN': 0, 'DDoS': 1, 'DoS GoldenEye': 2, 'DoS Hulk': 3, 'DoS Slowhttptest': 4, 'DoS slowloris': 5, 'FTP-Patator': 6, 'Other_Attack': 7, 'PortScan': 8, 'SSH-Patator': 9}\n",
      "0    63101\n",
      "3     5162\n",
      "8     4373\n",
      "1     3618\n",
      "2      291\n",
      "6      189\n",
      "5      162\n",
      "4      155\n",
      "9      138\n",
      "7      116\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# is there a reasonabke order??? maybe\n",
    "\n",
    "\n",
    "# Create encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the Label column\n",
    "df['Label'] = le.fit_transform(df['Label'])\n",
    "\n",
    "# Optional: see the mapping of classes\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label mapping:\", label_mapping)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed7bfb51-5414-4f1c-af51-7a1d2085d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separe features and labels\n",
    "# X = features, y = target\n",
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58b0f190-fd99-4845-8f9a-21ecd0534a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (61844, 44)\n",
      "Val shape: (15461, 44)\n"
     ]
    }
   ],
   "source": [
    "# train/vasl split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,      # preserves class distribution\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Val shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b57bd-29cd-4dc5-b0a8-188a783ec8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba9e09-695c-4e2c-964b-af0745422794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49719342-e22b-476d-99ba-f0b90c5ed342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46319995-f597-42e7-bd6f-fec442036d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52fd20f8-0bb8-4582-9eb5-23477f8c8bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    50481\n",
      "3     4130\n",
      "8     3498\n",
      "1     2894\n",
      "2      233\n",
      "6      151\n",
      "5      130\n",
      "4      124\n",
      "9      110\n",
      "7       93\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e68913c-c5c3-453b-82a1-617b1575e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote in here!!!!!!!!\n",
    "smote = SMOTE(sampling_strategy=0.3, random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3db1cc2a-cfc3-4e7f-98e6-d928c6dee2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    50481\n",
      "3    50481\n",
      "1    50481\n",
      "8    50481\n",
      "4    50481\n",
      "5    50481\n",
      "2    50481\n",
      "6    50481\n",
      "9    50481\n",
      "7    50481\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14e57b-3e9f-4c0c-baf9-66fee5fa2e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8220d51-6109-4536-97b5-7921c5b262e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f7a9a-a57f-4bc7-a70d-d67ed30e26cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c2653-f97c-427f-b355-8cb56137cf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c897efc-afdc-4278-88f7-5163b7e26350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98a80436-e94f-4777-96d9-3e6aa3965ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for those moldes that needs it: scaling\n",
    "\n",
    "# Suppose X_train, X_val, X_test are your features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 1️⃣ Fit only on training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# 2️⃣ Transform train, validation, and test\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "X_val_scaled = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e36bea50-febc-4495-9c6b-8beb20c65c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch datasets\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Convert data to PyTorch tensors\n",
    "# -----------------------------\n",
    "X_train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_scaled.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c35e3-f665-40a6-ae4c-64e86d6bd798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de29f1-4bfe-4f2f-ae20-da32f5234b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bf8166f-114c-4777-ac4c-7a705225a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Putting all together\n",
    "\n",
    "# combine functions for preprocessing\n",
    "\n",
    "def preprocessing(path, features, do_smote=True, sampling_strategy=0.3, batch_size=64):\n",
    "    # load data\n",
    "    df = pd.read_csv(path)\n",
    "    # drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna()    \n",
    "    # handle inf\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df = df.dropna()\n",
    "    # features to keep\n",
    "    df = df[keep_features]\n",
    "    # combine rare attacks\n",
    "    rare_attacks = ['Bot', 'Web Attack � Brute Force', 'Web Attack � XSS']\n",
    "    df['Label'] = df['Label'].apply(lambda x: 'Other_Attack' if x in rare_attacks else x)\n",
    "    # label encoding\n",
    "    le = LabelEncoder()\n",
    "    df['Label'] = le.fit_transform(df['Label'])\n",
    "    # separe features and labels\n",
    "    X = df.drop('Label', axis=1)\n",
    "    y = df['Label']\n",
    "    # train/val split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        stratify=y,      # preserves class distribution\n",
    "        random_state=42\n",
    "    )\n",
    "    # smote\n",
    "    if do_smote:\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    # scale (only for nnets)\n",
    "    if do_scale:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "        X_val = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns)\n",
    "\n",
    "    # create dataloaders\n",
    "    X_train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "    \n",
    "    X_val_tensor = torch.tensor(X_val_scaled.values, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f0b38-911c-4b94-bee1-0795260c2183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc0628f-1bce-4f5a-ae6a-16d69fcc47ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc854c7a-321d-4503-bd98-d19899323d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47472cb4-0c86-41cc-b2a0-641de07bb71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ecb3e-6b0b-43ff-bc13-d4ec3cf19754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae8e5f-28d8-47b5-be77-ba99bbd4f686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecc7ac-5675-4d67-99c9-36eeacbf760b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95966581-5be2-461f-b6e9-666f72a7c6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9220c7ad-3437-4784-b41b-b3468844ff4d",
   "metadata": {},
   "source": [
    "# smote\n",
    "\n",
    "✅ Recommended order for your pipeline\n",
    "\n",
    "Drop nulls / clean data\n",
    "→ SMOTE can’t handle missing values, so clean first.\n",
    "\n",
    "Combine rare classes / categories\n",
    "→ Do this before encoding, so you don’t generate rare dummy variables.\n",
    "\n",
    "Feature selection\n",
    "→ Optional before resampling, but ensure you keep the features SMOTE will use.\n",
    "\n",
    "Label encoding / one-hot encoding\n",
    "→ Yes, do this before SMOTE.\n",
    "SMOTE works on numeric data, not strings or categories.\n",
    "\n",
    "Separate features and labels (X, y)\n",
    "→ Required for SMOTE.\n",
    "\n",
    "Train/validation split\n",
    "⚠️ Important:\n",
    "Apply SMOTE only on the training set, never before splitting.\n",
    "Otherwise, synthetic samples will leak into validation data and inflate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a63c7def-de68-4683-8a55-48b85a970455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import train_test_split\\nfrom imblearn.over_sampling import SMOTE\\n\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\\n\\nsmote = SMOTE(random_state=42)\\nX_train_res, y_train_res = smote.fit_resample(X_train, y_train)\\n\\n\\n# scaling (if needed)\\nscaler.fit(X_train_res)\\nX_train_scaled = scaler.transform(X_train_res)\\nX_val_scaled = scaler.transform(X_val)\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# scaling (if needed)\n",
    "scaler.fit(X_train_res)\n",
    "X_train_scaled = scaler.transform(X_train_res)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5229e062-cecb-44c5-b16b-723057f7c341",
   "metadata": {},
   "source": [
    "| Step               | Apply SMOTE before/after?     |\n",
    "| ------------------ | ----------------------------- |\n",
    "| Drop nulls         | Before                        |\n",
    "| Combine rare cases | Before                        |\n",
    "| Encode categorical | Before                        |\n",
    "| Split train/val    | Before                        |\n",
    "| SMOTE              | ✅ After split (only on train) |\n",
    "| Scaling            | After SMOTE                   |\n",
    "\n",
    "\n",
    "\n",
    "de (clean → encode → split → SMOTE → scale → train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d019356-e345-4850-a42d-6869ba2c7907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b4ce8-02fc-4bfa-9083-018fcdf22897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b6ab7-7cea-4300-9db9-cc490e313ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce67860-8054-4466-bd56-e954bb4f5b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea2b04-9310-4566-a0b4-4bd955582888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b09c3-69bf-43c3-a685-6dda4ae06735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
